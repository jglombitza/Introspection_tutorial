{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jglombitza/Introspection_tutorial/blob/main/activation_maximization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHlw-6V2-ron"
      },
      "source": [
        "## Activation maximization\n",
        "In this task, we use the approach of activation maximization to visualize to which patterns features of a CNN trained using on MNIST are sensitive. This will give us a deeper understanding of the working principle of CNNs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgiFpHa7-roo",
        "outputId": "074c413d-cc81-4b0b-ce09-b4716e120db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keras 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "KTF = keras.backend\n",
        "layers = keras.layers\n",
        "\n",
        "print(\"keras\", keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tNIf_J0-ror"
      },
      "source": [
        "### Download and preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F4IVsOjF-ror"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype(np.float32)[...,np.newaxis] / 255.\n",
        "x_test = x_test.astype(np.float32)[...,np.newaxis] / 255.\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OKPtmhI-ros"
      },
      "source": [
        "### Set up a convolutional neural network with at least 4 CNN layers.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Task 1:**\n",
        "- Update the model to feature more than a single Convolutional layer.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P-abATU-ros",
        "outputId": "d6e9fde1-2d42-4b6d-ad5a-6c162054fea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 16)               0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                170       \n",
            "                                                                 \n",
            " softmax_layer (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330\n",
            "Trainable params: 330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential()\n",
        "model = keras.models.Sequential([\n",
        "    layers.Conv2D(16, (3,3), activation='relu', padding='same', input_shape=(28,28,1), name='conv2d_1'),\n",
        "    layers.GlobalMaxPooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10),\n",
        "    layers.Activation('softmax', name='softmax_layer')])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97or9ODs-rou"
      },
      "source": [
        "#### compile and train model\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Task 2:**\n",
        "- Train the model until convergence. (Usually for MNIST not more than 20 epochs!)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgZfb59--rou",
        "outputId": "f434421c-03dc-4b4f-80fe-fe94b0a54ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "540/540 [==============================] - 21s 37ms/step - loss: 2.2888 - accuracy: 0.1466 - val_loss: 2.2427 - val_accuracy: 0.3318\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "results = model.fit(x_train, y_train,\n",
        "                    batch_size=100,\n",
        "                    epochs=1,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDONY5Kq-rov"
      },
      "source": [
        "### Implementation of activation maximization\n",
        "Select a layer you want to visualize and perform activation maximization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JklMuNzU-rox"
      },
      "outputs": [],
      "source": [
        "gradient_updates = 50\n",
        "step_size = 1.\n",
        "\n",
        "def normalize(x):\n",
        "    '''Normalize gradients via l2 norm'''\n",
        "    return x / (KTF.sqrt(KTF.mean(KTF.square(x))) + KTF.epsilon())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HKBVm3l-roy"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Task 3:**\n",
        "In the following, implement activation maximization to visualize to which patterns a specific feature map is sensitive:\n",
        "- Start from a uniform distributed noise 'image' (note that the shape has to be `(1, 28, 28, 1)`, as we use a batch size of `1`).\n",
        "- Choose one specific feature map using 'filter_index' from your tensor of activations `layer_output`\n",
        "- Create a scalar loss as discussed in Chapter 12 (maximize the average feature map activation). Make use of `KTF.mean()`, which averages of the tensor.\n",
        "- \n",
        "- Thereafter, calculated gradients with respect to your starting 'image' (gradient ascent step) and repeat the procedure using `gradient_updates = 50`. \n",
        "You can calculate the gradients using the following expression:\n",
        "`grads = gtape.gradient(YOUR_OBJECTIVE, THE_VARIABLE_YOU_WANT_TO_OPTIMIZE)` \n",
        "- Then, normalize the gradients using: `grads = normalize(grads)` (already in the code)\n",
        "- Finally, implement the gradient ascent step (you may use `assign_sub` or `assign_add` to adapt the parameters).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*Remember to construct a Keras variable `KTF.variable(...)` for the input (we want to find an input that 'maximizes' the output, so we build an input that holds adaptive parameters which we can train using TensorFlow / Keras)*\n",
        "The following code snippet may help you to implement the maximization: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwMQF_B--roz"
      },
      "outputs": [],
      "source": [
        "visualized_feature = []  # list of visualized feature maps\n",
        "layer_dict = layer_dict = dict([(layer.name, layer) for layer in model.layers[:]])\n",
        "layer_name = \"conv2d_3\"  # visualize third layer\n",
        "\n",
        "layer_output = layer_dict[layer_name].output\n",
        "print(\"shape of layer output (tensor of activations):\", layer_output.shape)\n",
        "sub_model = keras.models.Model([model.inputs], [layer_output])\n",
        "\n",
        "# activation maximization\n",
        "for filter_index in range(layer_output.shape[-1]):  # iterate over feature maps\n",
        "    print('Processing filter %d' % (filter_index+1))\n",
        "    input_img = KTF.variable([0]) # instead of '[0]' use noise as the (start) input image with correct shape\n",
        "\n",
        "    for i in range(gradient_updates):\n",
        "\n",
        "        with tf.GradientTape() as gtape:\n",
        "            layer_output = sub_model(input_img)  # propagation of the \"image\" through you model to a given layer. Output is tensor of all activations in all feature maps\n",
        "\n",
        "            loss = 0  # <--: define your scalar loss HERE using keras and layer_output\n",
        "            # <-- estimate gradients here\n",
        "            grads = normalize(grads)\n",
        "            # <-- perform gradient ascent here\n",
        "\n",
        "    visualized_feature.append(input_img.numpy())  # cast to numpy array"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hints:**\n",
        "- You can generate uniform noise using: `np.random.uniform(0,1, shape)`\n",
        "- As loss we introducted the average response of the feature map: $1/n_{pix} \\sum_{ij} h_{ij}$, where $ij$ are the pixel indexes (height and width).\n",
        "Thus, we need to implement it via: `loss = KTF.mean(layer_output[..., filter_index])`."
      ],
      "metadata": {
        "id": "xBnUgM46At2E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJsGBRy0-ro0"
      },
      "source": [
        "#### Plot images to visualize to which patterns the respective feature maps are sensitive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1hXl_5U-ro0"
      },
      "outputs": [],
      "source": [
        "def deprocess_image(x):\n",
        "    # reprocess visualization to format of \"MNIST images\"\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + KTF.epsilon())\n",
        "    # x *= 0.1\n",
        "    x += 0.5\n",
        "    x *= 255\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjUJaehf-ro1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for i, feature_ in enumerate(visualized_feature):\n",
        "    feature_image = deprocess_image(feature_)\n",
        "    ax = plt.subplot(8,8, 1+i, )\n",
        "    plt.imshow(feature_image.squeeze())\n",
        "    ax.axis('off')\n",
        "    plt.title(\"feature %s\" % i)\n",
        "    \n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Dream on MNIST\n",
        "**Bonus**\n",
        "If you finished the task very fast, perform activation maximization using other objectives, e.g., the deep dream loss."
      ],
      "metadata": {
        "id": "tpWzCiQIJ3No"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "activation_maximization.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
